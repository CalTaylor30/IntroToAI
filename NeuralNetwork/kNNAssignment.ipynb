{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccec83ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def loadData(fileName):\n",
    "    data = []\n",
    "    with open(fileName, 'r') as f:\n",
    "        for line in f:\n",
    "            row = list(map(float, line.strip().split(',')))\n",
    "            data.append(row)\n",
    "    return torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "trainingSet = loadData(\"yeast_train.txt\")\n",
    "testingSet = loadData(\"yeast_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad2e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDistance(x, y):\n",
    "    return torch.sqrt(torch.sum((x - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6eaa4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(trainingSet, tester, k):\n",
    "    distances = []\n",
    "    for i in range(trainingSet.shape[0]):\n",
    "        dist = getDistance(tester, trainingSet[i][:-1])\n",
    "        distances.append((dist, trainingSet[i][-1], i))\n",
    "    distances.sort(key=lambda x: (x[0], x[2]))\n",
    "\n",
    "    neighbors = [distances[i][1].item() for i in range(k)]\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17932ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guessClass(neighbors, classOrder):\n",
    "    \n",
    "    if(len(neighbors) > 1):\n",
    "        \n",
    "        labels = [label for label in neighbors]\n",
    "\n",
    "        mostVotes = max(Counter(labels).values())\n",
    "        options = [label for label, total in Counter(labels).items() if total == mostVotes]\n",
    "\n",
    "        for cls in classOrder:\n",
    "            if cls in options:\n",
    "                return cls\n",
    "    else:\n",
    "        return neighbors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00844869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mykNN(trainingSet, testingSet, k):\n",
    "    classOrder = []\n",
    "    for label in trainingSet[:, -1]:\n",
    "        if label not in classOrder:\n",
    "            classOrder.append(label)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(testingSet.shape[0]):\n",
    "        tester = testingSet[i, :-1]\n",
    "        actual = testingSet[i, -1].item()\n",
    "        neighbors = getNeighbors(trainingSet, tester[0], k)\n",
    "        guess = guessClass(neighbors, classOrder)\n",
    "        predictions.append((guess, actual))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ea73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loocv(trainingSet, k):\n",
    "    errors = []\n",
    "\n",
    "    for i in range(trainingSet.shape[0]):\n",
    "        trainer = torch.cat((trainingSet[:i], trainingSet[i+1:]))\n",
    "        tester = trainingSet[i, :-1]\n",
    "\n",
    "        predicted = mykNN(trainer, tester.unsqueeze(0), k)[0][0]\n",
    "        actual = trainingSet[i, -1].item()\n",
    "\n",
    "        errors.append(abs(predicted - actual))\n",
    "    return sum(errors) / len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runkNN(trainingSet, testingSet):\n",
    "    \n",
    "    errors = []\n",
    "    \n",
    "    for k in range(1,4):\n",
    "        mae = loocv(trainingSet, k+1)\n",
    "        errors.append((mae, k+1))\n",
    "        \n",
    "    errors.sort()\n",
    "    bestK = errors[0][1]\n",
    "\n",
    "    print(f\"K chosen to be: {bestK}\")\n",
    "\n",
    "    predictions = mykNN(trainingSet, testingSet, bestK)\n",
    "\n",
    "    correct = 0\n",
    "    totalError = 0\n",
    "    for guess, actual in predictions:\n",
    "        if guess == actual:\n",
    "            correct += 1\n",
    "        totalError += abs(guess - actual)\n",
    "    \n",
    "    print(f\"Predicted Class Label: {guess}, Actual Class Label: {actual}\")\n",
    "    print(f\"Correctly Classified Instances: {correct}, Total Instances Predicted: {len(predictions)}\")\n",
    "    print(f\"Mean Absolute Error: {totalError / len(predictions)}, Total Instances Predicted: {len(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runkNN(trainingSet, testingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "741fdecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confMatrix(predictions, numClasses):\n",
    "    matrix = np.zeros((numClasses, numClasses), dtype=int)\n",
    "\n",
    "    for guess, actual in predictions:\n",
    "        matrix[int(actual)][int(guess)] += 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f7d590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotkNN(trainingSet, testingSet):\n",
    "    accuracies = []\n",
    "\n",
    "    numClasses = len(set(trainingSet[:, -1].tolist() + testingSet[:, -1].tolist()))\n",
    "\n",
    "    kVals = [1,5,10,20,30]\n",
    "    for k in kVals:\n",
    "        predictions = mykNN(trainingSet, testingSet, k)\n",
    "        if k == 1 or k == 30:\n",
    "            matrix = confMatrix(predictions, numClasses)\n",
    "            print(f\"Confusion Matrix for k={k}:\\n{matrix}\\n\")\n",
    "        correct = sum(1 for guess, actual in predictions if guess == actual)\n",
    "        acc = correct / len(predictions)\n",
    "        accuracies.append(acc)\n",
    "    \n",
    "    plt.plot(kVals, accuracies, marker=\"o\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Test Accuracy\")\n",
    "    plt.title(\"Accuracy vs k on Yeast Dataset\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1703411",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 11 is out of bounds for axis 0 with size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mplotkNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainingSet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestingSet\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mplotkNN\u001b[39m\u001b[34m(trainingSet, testingSet)\u001b[39m\n\u001b[32m      8\u001b[39m predictions = mykNN(trainingSet, testingSet, k)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m k == \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m k == \u001b[32m30\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     matrix = \u001b[43mconfMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumClasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConfusion Matrix for k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmatrix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m correct = \u001b[38;5;28msum\u001b[39m(\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m guess, actual \u001b[38;5;129;01min\u001b[39;00m predictions \u001b[38;5;28;01mif\u001b[39;00m guess == actual)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mconfMatrix\u001b[39m\u001b[34m(predictions, numClasses)\u001b[39m\n\u001b[32m      2\u001b[39m matrix = np.zeros((numClasses, numClasses), dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m guess, actual \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mactual\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;28mint\u001b[39m(guess)] += \u001b[32m1\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m matrix\n",
      "\u001b[31mIndexError\u001b[39m: index 11 is out of bounds for axis 0 with size 11"
     ]
    }
   ],
   "source": [
    "plotkNN(trainingSet, testingSet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
